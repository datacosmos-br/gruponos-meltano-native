"""Orquestrador Nativo Meltano GrupoNOS - ImplementaÃ§Ã£o especÃ­fica GrupoNOS.

Este mÃ³dulo fornece toda a orquestraÃ§Ã£o especÃ­fica do GrupoNOS para pipelines Meltano
com sistemas Oracle WMS, construÃ­do sobre padrÃµes de arquitetura empresarial.

Refactored to use modular architecture with separated concerns:
- Pipeline models in models/pipeline.py
- Pipeline execution in core/pipeline_executor.py
- Orchestration logic focused on high-level coordination

Copyright (c) 2025 Grupo NÃ³s. Todos os direitos reservados. LicenÃ§a: ProprietÃ¡ria
"""

from __future__ import annotations

import os
import subprocess  # noqa: S404
import time
from datetime import UTC, datetime
from pathlib import Path
from typing import Self

from flext_core import FlextResult, FlextService, FlextTypes as t
from flext_meltano import FlextMeltanoService

from gruponos_meltano_native.config import GruponosMeltanoNativeConfig
from gruponos_meltano_native.models.pipeline import GruponosMeltanoNativeModels

# Constants for validation
MAX_PORT_NUMBER = 65535
MAX_JOB_NAME_LENGTH = 100

# Use imported models directly
m = GruponosMeltanoNativeModels

# Short aliases for types
PipelineResult = m.PipelineResult

# =============================================
# GRUPONOS MELTANO PIPELINE RESULT
# =============================================


class GruponosMeltanoPipelineResult:
    """Classe que representa o resultado de uma execuÃ§Ã£o de pipeline ETL.

    Contendo informaÃ§Ãµes de sucesso, tempos de execuÃ§Ã£o, saÃ­das e metadados.

    Attributes:
        success: Indica se a execuÃ§Ã£o foi bem-sucedida.
        job_name: Nome do job/pipeline executado.
        execution_time: Tempo de execuÃ§Ã£o em segundos.
        output: SaÃ­da padrÃ£o do pipeline.
        error: Mensagem de erro, se houver.
        metadata: Metadados adicionais da execuÃ§Ã£o.

    """

    success: bool
    job_name: str
    execution_time: float
    output: str
    error: str | None
    metadata: dict[str, t.GeneralValueType] | None

    def __init__(
        self,
        *,
        success: bool,
        job_name: str,
        execution_time: float,
        output: str,
        error: str | None = None,
        metadata: dict[str, t.GeneralValueType] | None = None,
    ) -> None:
        """Initialize pipeline result."""
        self.success = success
        self.job_name = job_name
        self.execution_time = execution_time
        self.output = output
        self.error = error
        self.metadata = metadata


# =============================================
# GRUPONOS MELTANO ORCHESTRATOR - UNIFIED CLASS
# =============================================


class GruponosMeltanoOrchestrator(FlextService[GruponosMeltanoNativeConfig]):
    """GrupoNOS Meltano Orchestrator - Unified class following FLEXT patterns.

    This orchestrator provides enterprise-grade ETL pipeline management for Oracle WMS
    to Oracle Database data integration operations. It coordinates Meltano pipeline
    execution with comprehensive error handling, monitoring, and business rule enforcement.

    Key Features:
      - Full synchronization pipeline for complete data refresh
      - Incremental synchronization for real-time data updates
      - Oracle WMS API integration with retry mechanisms
      - Target database operations with transaction management
      - Comprehensive monitoring and alerting integration

    Architecture:
      Built on Clean Architecture principles with dependency injection,
      the orchestrator serves as the main application service layer that
      coordinates between domain logic and infrastructure concerns.

    Example:
      Basic orchestrator usage:

      >>> orchestrator = GruponosMeltanoOrchestrator()
      >>> result = orchestrator.run_full_sync()
      >>> if result.success:
      ...     print(f"Pipeline completed in {result.execution_time:.2f}s")
      ... else:
      ...     print(f"Pipeline failed: {result.error}")

    Integration:
      - Uses GruponosMeltanoNativeConfig for environment-aware configuration
      - Integrates with flext-meltano for execution (ZERO TOLERANCE for direct subprocess)
      - Coordinates with monitoring systems for observability
      - Implements enterprise patterns for consistent error handling

    """

    settings: GruponosMeltanoNativeConfig
    _meltano_service: FlextMeltanoService

    def __new__(
        cls,
        settings: GruponosMeltanoNativeConfig | None = None,  # noqa: ARG004
    ) -> Self:
        """Create orchestrator instance with optional settings."""
        return super().__new__(cls)

    def __init__(self, settings: GruponosMeltanoNativeConfig | None = None) -> None:
        """Inicializa orquestrador com configuraÃ§Ãµes GrupoNOS.

        Args:
            settings: ConfiguraÃ§Ãµes opcionais Meltano GrupoNOS.
                     Se None, as configuraÃ§Ãµes serÃ£o carregadas das variÃ¡veis
                     de ambiente e arquivos de configuraÃ§Ã£o usando padrÃµes default.

        Raises:
            GruponosMeltanoConfigurationError: Se configuraÃ§Ã£o obrigatÃ³ria estiver ausente.
            GruponosMeltanoValidationError: Se a validaÃ§Ã£o da configuraÃ§Ã£o falhar.

        Example:
            >>> # Usar configuraÃ§Ãµes padrÃ£o do ambiente
            >>> orchestrator = GruponosMeltanoOrchestrator()

            >>> # Usar configuraÃ§Ãµes customizadas
            >>> custom_settings = GruponosMeltanoNativeConfig(environment="production")
            >>> orchestrator = GruponosMeltanoOrchestrator(custom_settings)

        """
        super().__init__()
        self.settings = settings or GruponosMeltanoNativeConfig()
        # Logger is provided by FlextMixins via property - no assignment needed
        self._meltano_service = FlextMeltanoService()

        # Validate initial configuration during initialization
        validation_result = self._validate_initial_configuration()
        if validation_result.is_failure:
            error_msg = (
                f"Initial configuration validation failed: {validation_result.error}"
            )
            self.logger.error(error_msg)
            init_error_msg = (
                f"Orchestrator initialization failed: {validation_result.error}"
            )
            raise ValueError(init_error_msg)

        self.logger.debug("GruponosMeltanoOrchestrator initialized successfully")

    def execute(self) -> FlextResult[GruponosMeltanoNativeConfig]:
        """Execute orchestrator validation and return configuration.

        This implements the abstract execute() method from FlextService.
        Returns the validated configuration as the result.
        """
        validation_result = self._validate_initial_configuration()
        if validation_result.is_failure:
            return FlextResult[GruponosMeltanoNativeConfig].fail(
                validation_result.error or "Configuration validation failed"
            )
        return FlextResult[GruponosMeltanoNativeConfig].ok(self.settings)

    # =============================================
    # PUBLIC API METHODS
    # =============================================

    def validate_configuration(self) -> FlextResult[None]:
        """Valida configuraÃ§Ã£o do orquestrador usando padrÃµes FLEXT.

        Executa validaÃ§Ã£o completa das configuraÃ§Ãµes necessÃ¡rias para
        operaÃ§Ã£o do orquestrador, incluindo conexÃµes Oracle e fonte WMS.

        Returns:
            FlextResult[None]: Indica sucesso ou falha com erros de validaÃ§Ã£o.

        Example:
            >>> orchestrator = GruponosMeltanoOrchestrator()
            >>> resultado = orchestrator.validate_configuration()
            >>> if resultado.success:
            ...     print("ConfiguraÃ§Ã£o vÃ¡lida")

        """
        # Configuration validation using FlextCore patterns
        config_dict = self.settings.model_dump()
        if not config_dict:
            return FlextResult.fail("Configuration is empty")

        # Basic validation - check required fields are present
        required_fields = [
            "meltano_project_root",
            "oracle_host",
            "oracle_username",
            "oracle_password",
        ]
        for field in required_fields:
            if not config_dict.get(field):
                return FlextResult.fail(f"Required field '{field}' is missing or empty")

        return FlextResult.ok(None)

    def run_full_sync(self) -> FlextResult[PipelineResult]:
        """Executa pipeline de sincronizaÃ§Ã£o completa para atualizaÃ§Ã£o total dos dados.

        Este mÃ©todo executa o pipeline ETL completo que extrai todos os dados
        da API Oracle WMS e os carrega no banco Oracle de destino. Ã‰ projetado
        para operaÃ§Ãµes de atualizaÃ§Ã£o completa de dados e cargas iniciais.

        Componentes do Pipeline:
            - ExtraÃ§Ã£o de dados da API Oracle WMS (todas as entidades)
            - ValidaÃ§Ã£o de dados e verificaÃ§Ãµes de qualidade
            - AplicaÃ§Ã£o de regras de negÃ³cio
            - Carga em lote no banco de destino com gerenciamento de transaÃ§Ãµes
            - Monitoramento e alertas abrangentes

        Returns:
            FlextResult[PipelineResult]: Railway-oriented result with
            pipeline execution details and comprehensive error handling.

        Example:
            >>> orchestrator = GruponosMeltanoOrchestrator()
            >>> result = orchestrator.run_full_sync()
            >>> if result.is_success:
            ...     pipeline_result = result.value
            ...     print(f"Sync completo em {pipeline_result.execution_time:.2f}s")
            ...     print(f"SaÃ­da: {pipeline_result.output}")
            ... else:
            ...     print(f"Sync completo falhou: {result.error}")

        Note:
            - Tempo tÃ­pico de execuÃ§Ã£o: 5-15 minutos para datasets padrÃ£o
            - Uso de memÃ³ria: 1-2GB pico durante operaÃ§Ãµes em lote
            - Agendamento recomendado: Semanal ou sob demanda

        FLEXT OPTIMIZATION:
        - Uses FlextResult for railway-oriented error handling
        - Comprehensive error reporting without exceptions
        - Type-safe result processing

        """
        sync_result = self._execute_meltano_pipeline("full-sync-job")

        if sync_result.is_failure:
            return FlextResult.fail(sync_result.error)

        _sync_value = sync_result.value

        pipeline_result = PipelineResult(
            pipeline_id=f"full-sync-{datetime.now(tz=UTC).isoformat()}",
            pipeline_name="full-sync-job",
            status="SUCCESS" if sync_result.is_success else "FAILED",
            start_time=datetime.now(tz=UTC),
            end_time=datetime.now(tz=UTC),
            duration_seconds=0.0,
            job_name="full-sync-job",
            records_extracted=0,
            records_loaded=0,
        )

        return FlextResult.ok(pipeline_result)

    def run_incremental_sync(self) -> FlextResult[PipelineResult]:
        """Executa pipeline de sincronizaÃ§Ã£o incremental para atualizaÃ§Ãµes em tempo real.

        Este mÃ©todo executa o pipeline ETL incremental que extrai apenas
        dados modificados desde a Ãºltima sincronizaÃ§Ã£o usando timestamps
        de modificaÃ§Ã£o. Ã‰ otimizado para execuÃ§Ã£o frequente e transferÃªncia mÃ­nima de dados.

        Componentes do Pipeline:
            - ExtraÃ§Ã£o incremental de dados da API Oracle WMS (filtro mod_ts)
            - Captura e validaÃ§Ã£o de dados modificados
            - OperaÃ§Ãµes de upsert no banco de destino
            - Monitoramento e alertas incrementais

        Returns:
            FlextResult[PipelineResult]: Railway-oriented result with
            incremental sync execution details and comprehensive error handling.

        Example:
            >>> orchestrator = GruponosMeltanoOrchestrator()
            >>> result = orchestrator.run_incremental_sync()
            >>> if result.is_success:
            ...     pipeline_result = result.value
            ...     print(
            ...         f"Sync incremental completo: {pipeline_result.execution_time:.2f}s"
            ...     )
            ...     # Acessar mÃ©tricas incrementais via pipeline_result.metadata
            ... else:
            ...     print(f"Sync incremental falhou: {result.error}")

        Note:
            - Tempo tÃ­pico de execuÃ§Ã£o: 30 segundos - 2 minutos
            - Uso de memÃ³ria: 100-500MB pico
            - Agendamento recomendado: A cada 2 horas

        FLEXT OPTIMIZATION:
        - Uses FlextResult for railway-oriented error handling
        - Comprehensive error reporting without exceptions
        - Type-safe result processing

        """
        sync_result = self._execute_meltano_pipeline("incremental-sync-job")

        if sync_result.is_failure:
            return FlextResult.fail(sync_result.error)

        _sync_value = sync_result.value

        pipeline_result = PipelineResult(
            pipeline_id=f"incremental-sync-{datetime.now(tz=UTC).isoformat()}",
            pipeline_name="incremental-sync-job",
            status="SUCCESS" if sync_result.is_success else "FAILED",
            start_time=datetime.now(tz=UTC),
            end_time=datetime.now(tz=UTC),
            duration_seconds=0.0,
            job_name="incremental-sync-job",
            records_extracted=0,
            records_loaded=0,
        )

        return FlextResult.ok(pipeline_result)

    def run_job(self, job_name: str) -> FlextResult[PipelineResult]:
        """Execute a specific pipeline job by name with railway-oriented error handling.

        Provides flexible job execution for custom pipeline configurations defined
        in the Meltano project. Supports both standard and custom job definitions.

        Args:
            job_name: Name of the Meltano job to execute. Must be defined in meltano.yml.

        Returns:
            FlextResult[PipelineResult]: Railway-oriented result with job execution details
            and performance metrics.

        Example:
            Flexible job execution with proper error handling:

            >>> orchestrator = GruponosMeltanoOrchestrator()
            >>> result = orchestrator.run_job("custom-data-quality-check")
            >>> if result.is_success:
            ...     job_result = result.value
            ...     print(f"âœ… Job '{job_result.job_name}' completed successfully")
            ... else:
            ...     logger.error(f"âŒ Job failed: {result.error}")

        Note:
            Available Jobs:
            - "full-sync-job": Complete data synchronization
            - "incremental-sync-job": Incremental data updates
            - Custom jobs as defined in meltano.yml

        FLEXT OPTIMIZATION:
        - Uses FlextResult for consistent error handling
        - Validates job name before execution
        - Comprehensive logging and monitoring
        - Structured error reporting

        """
        # Validate job name
        if not job_name or not job_name.strip():
            error_msg = "Job name cannot be empty"
            self.logger.error(error_msg)
            return FlextResult.fail(error_msg)

        sanitized_job_name = job_name.strip()
        self.logger.info(f"Starting job execution: {sanitized_job_name}")

        # Execute job with comprehensive error handling
        execution_result = self._execute_meltano_pipeline(sanitized_job_name)

        if execution_result.is_failure:
            self.logger.error(f"Job execution failed: {execution_result.error}")
            return FlextResult.fail(execution_result.error)

        _execution_value = execution_result.value
        job_result = PipelineResult(
            pipeline_id=f"job-{sanitized_job_name}-{datetime.now(tz=UTC).isoformat()}",
            pipeline_name=sanitized_job_name,
            status="SUCCESS",
            start_time=datetime.now(tz=UTC),
            end_time=datetime.now(tz=UTC),
            duration_seconds=0.0,
            job_name=sanitized_job_name,
            records_extracted=0,
            records_loaded=0,
        )

        self.logger.info(
            "Job execution completed successfully",
            extra={
                "job_name": sanitized_job_name,
                "duration_seconds": job_result.duration_seconds or 0.0,
                "records_loaded": job_result.records_loaded,
            },
        )

        return FlextResult.ok(job_result)

    def list_jobs(self) -> list[str]:
        """List all available pipeline jobs with FLEXT integration.

        Returns a list of all Meltano jobs available for execution in the current
        project configuration. Jobs are defined in meltano.yml and may include
        both standard ETL jobs and custom operations.

        Returns:
            list[str]: List of available job names that can be executed
            via run_job() method.

        Example:
            Listing available jobs with proper error handling:

            >>> orchestrator = GruponosMeltanoOrchestrator()
            >>> jobs = orchestrator.list_jobs()
            >>> print(f"ðŸ“‹ Available jobs: {', '.join(jobs)}")
            ðŸ“‹ Available jobs: full-sync-job, incremental-sync-job

        Note:
            Job list is currently hardcoded but should be improved to read
            dynamically from meltano.yml configuration in future versions.

        FLEXT OPTIMIZATION:
        - Uses FlextTypes for type safety
        - Comprehensive documentation with examples
        - Structured logging integration

        """
        available_jobs = ["full-sync-job", "incremental-sync-job"]
        self.logger.debug(f"Available jobs: {available_jobs}")
        return available_jobs

    def list_pipelines(self) -> list[str]:
        """List available pipelines (alias for list_jobs).

        Returns:
            list[str]: List of available pipeline names.

        Note:
            This is an alias for list_jobs() for backward compatibility.

        """
        return self.list_jobs()

    def run_pipeline(
        self,
        pipeline_name: str,
    ) -> FlextResult[PipelineResult]:
        """Execute pipeline asynchronously (compatibility method).

        Args:
            pipeline_name: Name of the pipeline to execute.

        Returns:
            FlextResult[PipelineResult]: Railway-oriented pipeline execution result.

        Note:
            This method provides backward compatibility. Use run_job() for new code.

        """
        return self.run_job(pipeline_name)

    def get_job_status(
        self, job_name: str
    ) -> FlextResult[dict[str, t.GeneralValueType]]:
        """Get status of a specific job with comprehensive information.

        Args:
            job_name: Name of the job to check status for.

        Returns:
            FlextResult[Dict]: Railway-oriented result containing job status information
            including availability and configuration details.

        Example:
            Checking job status with error handling:

            >>> orchestrator = GruponosMeltanoOrchestrator()
            >>> status_result = orchestrator.get_job_status("full-sync-job")
            >>> if status_result.is_success:
            ...     status = status_result.value
            ...     print(f"Job available: {status['available']}")
            ... else:
            ...     logger.error(f"Failed to get job status: {status_result.error}")

        FLEXT OPTIMIZATION:
        - Uses FlextResult for consistent error handling
        - Comprehensive status information
        - Type-safe return values

        """
        if not job_name or not job_name.strip():
            return FlextResult.fail("Job name cannot be empty")

        job_status: dict[str, t.GeneralValueType] = {
            "job_name": job_name.strip(),
            "available": job_name.strip() in self.list_jobs(),
            "settings": self.settings.model_dump(),
            "environment": self.settings.meltano_environment,
        }

        self.logger.debug(f"Job status retrieved: {job_status}")
        return FlextResult.ok(job_status)

    # =============================================
    # NESTED HELPER CLASSES
    # =============================================

    class _PipelineRunner:
        """Nested pipeline runner helper with retry logic and FLEXT integration.

        Provides advanced pipeline execution capabilities including retry mechanisms,
        exponential backoff, and comprehensive error handling following FLEXT patterns.
        """

        def __init__(self, orchestrator: GruponosMeltanoOrchestrator) -> None:
            """Initialize pipeline runner with orchestrator reference.

            Args:
                orchestrator: The parent orchestrator instance.

            FLEXT OPTIMIZATION:
            - Nested helper class following single-class pattern
            - Reference to parent orchestrator for state management
            - Type-safe initialization

            """
            super().__init__()
            self._orchestrator = orchestrator
            # Logger provided by orchestrator reference

        def run_with_retry(
            self,
            job_name: str,
            max_retries: int = 3,
        ) -> FlextResult[PipelineResult]:
            """Execute pipeline with comprehensive retry logic and error handling.

            Implements exponential backoff retry mechanism with detailed logging
            and metadata tracking for failed attempts.

            Args:
                job_name: Name of the job to execute with retry.
                max_retries: Maximum number of retry attempts (default: 3).

            Returns:
                FlextResult[PipelineResult]: Railway-oriented result with retry metadata.

            Example:
                Pipeline execution with retry logic:

                >>> runner = orchestrator._PipelineRunner(orchestrator)
                >>> result = runner.run_with_retry("full-sync-job", max_retries=5)
                >>> if result.is_success:
                ...     print("Pipeline succeeded after retries")
                ... else:
                ...     print(f"All retry attempts failed: {result.error}")

            FLEXT OPTIMIZATION:
            - Uses FlextResult for railway-oriented error handling
            - Exponential backoff with configurable retries
            - Comprehensive logging and metadata tracking
            - Type-safe implementation

            """
            self._orchestrator.logger.info(
                f"Starting pipeline execution with retry: {job_name}"
            )

            for attempt in range(max_retries + 1):
                attempt_num = attempt + 1
                self._orchestrator.logger.debug(
                    f"Attempt {attempt_num}/{max_retries + 1} for job: {job_name}"
                )

                try:
                    # Execute job using orchestrator's railway pattern
                    result = self._orchestrator.run_job(job_name)

                    if result.is_success:
                        self._orchestrator.logger.info(
                            f"Pipeline succeeded on attempt {attempt_num}",
                            extra={"job_name": job_name, "attempts": attempt_num},
                        )
                        return result

                    # Job failed, prepare for retry
                    if attempt < max_retries:
                        backoff_seconds = 2**attempt  # Exponential backoff
                        self._orchestrator.logger.warning(
                            f"Pipeline attempt {attempt_num} failed, retrying in {backoff_seconds}s",
                            extra={
                                "job_name": job_name,
                                "backoff_seconds": backoff_seconds,
                            },
                        )
                        time.sleep(backoff_seconds)

                except Exception as e:
                    error_msg = (
                        f"Pipeline execution failed on attempt {attempt_num}: {e}"
                    )
                    self._orchestrator.logger.exception(error_msg)

                    if attempt < max_retries:
                        backoff_seconds = 2**attempt
                        self._orchestrator.logger.info(
                            f"Retrying after {backoff_seconds}s due to exception"
                        )
                        time.sleep(backoff_seconds)

            # All attempts failed
            final_error = (
                f"All {max_retries + 1} retry attempts failed for job: {job_name}"
            )
            self._orchestrator.logger.error(
                final_error, extra={"job_name": job_name, "max_retries": max_retries}
            )

            return FlextResult.fail(final_error)

    # =============================================
    # PRIVATE METHODS
    # =============================================

    def _execute_meltano_pipeline(
        self, job_name: str
    ) -> FlextResult[dict[str, t.GeneralValueType]]:
        """Execute a Meltano pipeline with comprehensive error handling.

        This method executes Meltano jobs via FlextUtilities with proper environment
        setup, timeout handling, and structured error reporting.

        Args:
            job_name: Name of the Meltano job to execute

        Returns:
            FlextResult[Dict]: Railway-oriented result containing execution details
            or comprehensive error information.

        FLEXT OPTIMIZATION:
        - Uses FlextResult for railway-oriented error handling
        - Comprehensive environment setup
        - Timeout protection and proper cleanup
        - Structured logging and error reporting
        - Type-safe implementation

        """
        start_time = time.time()
        sanitized_job_name: str | None = None

        try:
            # Validate and sanitize job name
            sanitized_job_name = self._validate_job_name(job_name)
            self.logger.info(f"Executing Meltano job: {sanitized_job_name}")

            # Build execution environment
            env = self._build_meltano_environment()

            # Prepare Meltano command
            cmd = ["meltano", "run", sanitized_job_name]

            # Set working directory
            working_dir = Path(self.settings.meltano_project_root or ".")

            self.logger.debug(
                f"Meltano command: {' '.join(cmd)}",
                extra={
                    "job_name": sanitized_job_name,
                    "working_dir": str(working_dir),
                    "environment": self.settings.meltano_environment,
                },
            )

            # Execute Meltano job with timeout protection
            process_result = subprocess.run(  # noqa: S603
                cmd,
                check=False,
                cwd=working_dir,
                env=env,
                capture_output=True,
                text=True,
                timeout=self.settings.pipeline_timeout_seconds,
            )

            execution_time = time.time() - start_time

            # Process execution results
            if process_result.returncode == 0:
                self.logger.info(
                    "Meltano job completed successfully",
                    extra={
                        "job_name": sanitized_job_name,
                        "execution_time": execution_time,
                        "return_code": process_result.returncode,
                    },
                )

                return FlextResult.ok({
                    "execution_time": execution_time,
                    "output": process_result.stdout.strip(),
                    "metadata": {
                        "return_code": process_result.returncode,
                        "stderr": process_result.stderr.strip(),
                        "job_name": sanitized_job_name,
                    },
                })

            # Job failed but process completed
            error_details = (
                f"Meltano job failed with return code {process_result.returncode}"
            )
            self.logger.error(error_details, extra={"job_name": sanitized_job_name})
            return FlextResult.ok({
                "execution_time": execution_time,
                "output": process_result.stdout.strip(),
                "metadata": {
                    "return_code": process_result.returncode,
                    "stderr": process_result.stderr.strip(),
                    "job_name": sanitized_job_name,
                },
            })

        except subprocess.TimeoutExpired:
            execution_time = time.time() - start_time
            timeout_error = f"Meltano job timed out after {execution_time:.2f}s"
            job_name_str = sanitized_job_name or job_name
            self.logger.exception(timeout_error, extra={"job_name": job_name_str})
            return FlextResult.fail(timeout_error)
        except FileNotFoundError:
            execution_time = time.time() - start_time
            meltano_error = (
                "Meltano executable not found. Ensure Meltano is installed and in PATH."
            )
            job_name_str = sanitized_job_name or job_name
            self.logger.exception(meltano_error, extra={"job_name": job_name_str})
            return FlextResult.fail(meltano_error)
        except Exception as e:
            execution_time = time.time() - start_time
            unexpected_error = f"Unexpected error during Meltano job execution: {e}"
            job_name_str = sanitized_job_name or job_name
            self.logger.exception(unexpected_error, extra={"job_name": job_name_str})
            return FlextResult.fail(unexpected_error)

    def _build_meltano_environment(self) -> dict[str, str]:
        """Build comprehensive environment variables for Meltano execution.

        Constructs a complete environment dictionary with all necessary configuration
        for Meltano pipeline execution, including Oracle WMS and database credentials.

        Returns:
            dict[str, str]: Environment variables dictionary for external command execution.

        FLEXT OPTIMIZATION:
        - Comprehensive environment setup
        - Type-safe configuration access
        - Proper credential handling
        - Structured logging integration

        """
        env = os.environ.copy()

        # Meltano core configuration
        env.update({
            "MELTANO_ENVIRONMENT": self.settings.meltano_environment,
            "MELTANO_PROJECT_ROOT": str(
                Path(self.settings.meltano_project_root or ".")
            ),
        })

        # Oracle WMS source configuration
        wms_config = self.settings.wms_source_config
        # Add WMS configuration to environment
        wms_base_url = wms_config.get("base_url") or ""
        wms_username = wms_config.get("username") or ""
        wms_password = wms_config.get("password") or ""
        wms_company_code = wms_config.get("company_code") or ""
        wms_facility_code = wms_config.get("facility_code") or ""

        env.update([
            ("TAP_ORACLE_WMS_BASE_URL", wms_base_url),
            ("TAP_ORACLE_WMS_USERNAME", wms_username),
            ("TAP_ORACLE_WMS_PASSWORD", wms_password),
            ("TAP_ORACLE_WMS_COMPANY_CODE", wms_company_code),
            ("TAP_ORACLE_WMS_FACILITY_CODE", wms_facility_code),
        ])

        # Oracle target database configuration
        oracle_config = self.settings.oracle_connection_config
        oracle_host = oracle_config.get("host") or ""
        oracle_port = str(oracle_config.get("port") or "")
        oracle_username = oracle_config.get("username") or ""
        oracle_password = oracle_config.get("password") or ""
        oracle_schema = oracle_config.get("schema") or ""

        env.update([
            ("FLEXT_TARGET_ORACLE_HOST", oracle_host),
            ("FLEXT_TARGET_ORACLE_PORT", oracle_port),
            ("FLEXT_TARGET_ORACLE_USERNAME", oracle_username),
            ("FLEXT_TARGET_ORACLE_PASSWORD", oracle_password),
            ("FLEXT_TARGET_ORACLE_SCHEMA", oracle_schema),
        ])

        # Handle service name vs SID (backward compatibility)
        service_name = oracle_config.get("service_name")
        if service_name:
            env["FLEXT_TARGET_ORACLE_SERVICE_NAME"] = str(service_name)

        sid = oracle_config.get("sid")
        if sid:
            env["FLEXT_TARGET_ORACLE_SID"] = str(sid)

        self.logger.debug(
            "Meltano environment configured",
            extra={
                "environment": self.settings.meltano_environment,
                "wms_base_url": wms_config.get("base_url", ""),
                "oracle_host": oracle_config.get("host", ""),
            },
        )

        return env

    def _validate_initial_configuration(self) -> FlextResult[None]:
        """Validate orchestrator configuration during initialization.

        Performs essential configuration validation required for orchestrator
        to function properly, ensuring all required settings are present.

        Returns:
            FlextResult[None]: Success if configuration is valid, failure with error details.

        FLEXT OPTIMIZATION:
        - Railway-oriented validation
        - Comprehensive error reporting
        - Structured logging

        """
        try:
            # Validate Meltano environment
            if not self.settings.meltano_environment:
                return FlextResult.fail("meltano_environment is required")

            # Validate project root exists
            project_root = Path(self.settings.meltano_project_root or ".")
            if not project_root.exists():
                return FlextResult.fail(
                    f"Meltano project root does not exist: {project_root}"
                )

            # Validate meltano.yml exists
            meltano_config = project_root / "meltano.yml"
            if not meltano_config.exists():
                return FlextResult.fail(
                    f"meltano.yml not found in project root: {project_root}"
                )

            # Validate pipeline timeout
            if self.settings.pipeline_timeout_seconds <= 0:
                return FlextResult.fail("pipeline_timeout_seconds must be positive")

            self.logger.debug("Initial configuration validation passed")
            return FlextResult.ok(None)

        except Exception as e:
            return FlextResult.fail(f"Configuration validation failed: {e}")

    def _validate_meltano_project(self) -> FlextResult[None]:
        """Validate Meltano project structure and configuration.

        Checks that the Meltano project is properly configured and all
        required files and settings are present.

        Returns:
            FlextResult[None]: Success if project is valid, failure with details.

        FLEXT OPTIMIZATION:
        - Comprehensive project validation
        - Detailed error reporting
        - Type-safe file operations

        """
        try:
            project_root = Path(self.settings.meltano_project_root or ".")

            # Check project structure
            required_files = ["meltano.yml", "requirements.txt"]
            for file_name in required_files:
                file_path = project_root / file_name
                if not file_path.exists():
                    return FlextResult.fail(f"Required file not found: {file_path}")

            # Check for meltano environment
            if not self.settings.meltano_environment:
                return FlextResult.fail("Meltano environment not configured")

            self.logger.debug("Meltano project validation passed")
            return FlextResult.ok(None)

        except Exception as e:
            return FlextResult.fail(f"Meltano project validation failed: {e}")

    def _validate_environment_configuration(self) -> FlextResult[None]:
        """Validate environment-specific configuration.

        Validates that all required environment variables and configuration
        settings are properly set for the current environment.

        Returns:
            FlextResult[None]: Success if environment config is valid, failure with details.

        FLEXT OPTIMIZATION:
        - Environment-aware validation
        - Comprehensive credential checking
        - Structured error reporting

        """
        try:
            # Validate WMS configuration
            wms_config = self.settings.wms_source_config
            required_wms_fields = ["base_url", "username", "password", "company_code"]
            for field in required_wms_fields:
                if not wms_config.get(field):
                    return FlextResult.fail(f"WMS {field} is required")

            # Validate Oracle configuration
            oracle_config = self.settings.oracle_connection_config
            required_oracle_fields = ["host", "port", "username", "password", "schema"]
            for field in required_oracle_fields:
                if not oracle_config.get(field):
                    return FlextResult.fail(f"Oracle {field} is required")

            # Validate port is valid
            try:
                port = int(oracle_config.get("port", 0))
                if port <= 0 or port > MAX_PORT_NUMBER:
                    return FlextResult.fail(
                        f"Oracle port must be between 1 and {MAX_PORT_NUMBER}"
                    )
            except (ValueError, TypeError):
                return FlextResult.fail("Oracle port must be a valid number")

            self.logger.debug("Environment configuration validation passed")
            return FlextResult.ok(None)

        except Exception as e:
            return FlextResult.fail(f"Environment configuration validation failed: {e}")

    def _validate_job_name(self, job_name: str) -> str:
        """Validate and sanitize job name to prevent command injection.

        Performs comprehensive validation of job names to ensure they are safe
        for use in subprocess calls and don't contain malicious characters.

        Args:
            job_name: Job name to validate and sanitize.

        Returns:
            str: Validated and sanitized job name.

        Raises:
            ValueError: If job_name is empty or contains invalid characters.

        Example:
            >>> orchestrator._validate_job_name("full-sync-job")
            'full-sync-job'

        FLEXT OPTIMIZATION:
        - Comprehensive input validation
        - Command injection prevention
        - Type-safe string handling
        - Structured error messages

        """
        if not job_name or not job_name.strip():
            error_msg = "Job name cannot be empty or whitespace-only"
            self.logger.error(error_msg, job_name=repr(job_name))
            raise ValueError(error_msg)

        sanitized_job_name = job_name.strip()

        # Define forbidden characters that could be used for command injection
        invalid_chars = [
            ";",
            "&",
            "|",
            "`",
            "$",
            "(",
            ")",
            "{",
            "}",
            "[",
            "]",
            '"',
            "'",
            "<",
            ">",
            "\\",
        ]

        if any(char in sanitized_job_name for char in invalid_chars):
            error_msg = f"Job name contains invalid characters: {sanitized_job_name}"
            self.logger.error(error_msg, job_name=sanitized_job_name)
            raise ValueError(error_msg)

        # Additional validation: reasonable length
        if len(sanitized_job_name) > MAX_JOB_NAME_LENGTH:
            error_msg = f"Job name too long (max {MAX_JOB_NAME_LENGTH} chars): {len(sanitized_job_name)}"
            self.logger.error(error_msg, job_name=sanitized_job_name)
            raise ValueError(error_msg)

        self.logger.debug(f"Job name validated: {sanitized_job_name}")
        return sanitized_job_name

    # =============================================
    # FACTORY METHODS - FLEXT PATTERN
    # =============================================

    @classmethod
    def create_orchestrator(
        cls,
        settings: GruponosMeltanoNativeConfig | None = None,
    ) -> GruponosMeltanoOrchestrator:
        """Create configured instance of GrupoNOS Meltano Orchestrator.

        Factory method for creating fully configured orchestrator instances
        with proper initialization and validation.

        Args:
            settings: Optional GruponosMeltanoNativeConfig instance.
                     If None, configuration will be loaded from environment.

        Returns:
            GruponosMeltanoOrchestrator: Fully configured orchestrator instance.

        Example:
            >>> orchestrator = GruponosMeltanoOrchestrator.create_orchestrator()
            >>> result = orchestrator.validate_configuration()
            >>> assert result.is_success

        FLEXT OPTIMIZATION:
        - Class method factory pattern
        - Comprehensive documentation
        - Type-safe configuration handling

        """
        return cls(settings)

    @classmethod
    def create_pipeline_runner(
        cls,
        settings: GruponosMeltanoNativeConfig | None = None,
    ) -> GruponosMeltanoOrchestrator._PipelineRunner:
        """Create configured instance of GrupoNOS pipeline runner.

        Factory method for creating pipeline runner instances with retry logic
        and comprehensive error handling.

        Args:
            settings: Optional GruponosMeltanoNativeConfig instance.
                     If None, configuration will be loaded from environment.

        Returns:
            GruponosMeltanoOrchestrator._PipelineRunner: Configured pipeline runner instance.

        Example:
            >>> runner = GruponosMeltanoOrchestrator.create_pipeline_runner()
            >>> result = runner.run_with_retry("full-sync-job")
            >>> assert result.is_success

        FLEXT OPTIMIZATION:
        - Class method factory pattern
        - Proper encapsulation of nested classes
        - Type-safe instance creation

        """
        orchestrator = cls(settings)
        return cls._PipelineRunner(orchestrator)


# =============================================
# BACKWARD COMPATIBILITY FUNCTIONS
# =============================================


def create_gruponos_meltano_orchestrator(
    settings: GruponosMeltanoNativeConfig | None = None,
) -> GruponosMeltanoOrchestrator:
    """Create GrupoNOS Meltano Orchestrator instance (backward compatibility).

    Args:
        settings: Optional GruponosMeltanoNativeConfig instance.

    Returns:
        GruponosMeltanoOrchestrator: Configured orchestrator instance.

    Note:
        This function is maintained for backward compatibility.
        Use GruponosMeltanoOrchestrator.create_orchestrator() for new code.

    """
    return GruponosMeltanoOrchestrator.create_orchestrator(settings)


def create_gruponos_meltano_pipeline_runner(
    settings: GruponosMeltanoNativeConfig | None = None,
) -> GruponosMeltanoOrchestrator._PipelineRunner:
    """Create GrupoNOS pipeline runner instance (backward compatibility).

    Args:
        settings: Optional GruponosMeltanoNativeConfig instance.

    Returns:
        GruponosMeltanoOrchestrator._PipelineRunner: Configured pipeline runner instance.

    Note:
        This function is maintained for backward compatibility.
        Use GruponosMeltanoOrchestrator.create_pipeline_runner() for new code.

    """
    return GruponosMeltanoOrchestrator.create_pipeline_runner(settings)


# =============================================
# BACKWARD COMPATIBILITY ALIASES
# =============================================

# Type aliases for backward compatibility

# Module-level exports with comprehensive API surface
__all__: list[str] = [
    "GruponosMeltanoOrchestrator",
    "GruponosMeltanoPipelineResult",
    "create_gruponos_meltano_orchestrator",
    "create_gruponos_meltano_pipeline_runner",
]
